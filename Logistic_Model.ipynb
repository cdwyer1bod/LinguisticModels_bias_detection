{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1921, 10) (166, 10) (263, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"./5gram-edits-train-sents-clean.csv\")\n",
    "dev = pd.read_csv(\"./5gram-edits-dev-sents-clean.csv\")\n",
    "test = pd.read_csv(\"./5gram-edits-test-sents-clean.csv\")\n",
    "print(train.shape, dev.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654 66 27 100 11 181 18070\n"
     ]
    }
   ],
   "source": [
    "bias_lexicon_file = open('./bias-lexicon/bias-lexicon.txt','r')\n",
    "implicatives_file = open('./bias_related_lexicons/implicatives_karttunen1971.txt','r')\n",
    "assertives_file = open('./bias_related_lexicons/assertives_hooper1975.txt','r')\n",
    "factives_file = open('./bias_related_lexicons/factives_hooper1975.txt','r')\n",
    "hedges_file = open('./bias_related_lexicons/hedges_hyland2005.txt','r')\n",
    "other_file = open('./bias_related_lexicons/other_lexicons.txt','r')\n",
    "report_verbs_file = open('./bias_related_lexicons/report_verbs.txt','r')\n",
    "entailments_file = open('./entailments/reverb_global_clsf_all_tncf_lambda_0.1.txt','r')\n",
    "bias_lexicon = bias_lexicon_file.read().strip().split('\\n')\n",
    "assertives = assertives_file.read().strip().split('\\n')[7:]\n",
    "factives = factives_file.read().strip().split('\\n')[7:]\n",
    "hedges = hedges_file.read().strip().split('\\n')[7:]\n",
    "other_lexicon = other_file.read().strip().split('\\n')\n",
    "report_verbs = report_verbs_file.read().strip().split('\\n')[9:]\n",
    "entailments_prestrip = entailments_file.read().strip().split('\\n')\n",
    "\n",
    "def entailment_sorter(arr, length_entailing_predicate = 1, orderXY=True):\n",
    "    '''\n",
    "    Takes entailment dataset and distills it into usable information. Use params to get\n",
    "    the output you want. X 'word' Y = True means first argument is X, second is Y. False\n",
    "    means first argument is Y and second is X. \n",
    "    If orderXY = True it includes the last 2 headers:\n",
    "    entailing predicate, entailed predicate, X.Y=T/F entailing pred., X.Y=T/F entailed pred.\n",
    "    '''\n",
    "    if orderXY:\n",
    "        data = []\n",
    "        for e in arr:\n",
    "            x, y = e.split('\\t')\n",
    "            if len(x.split()) <= length_entailing_predicate:\n",
    "                x_arg, y_arg = True, True\n",
    "                if '@R@' in x: x_arg = False\n",
    "                if '@R@' in y: y_arg = False\n",
    "                data.append([x.replace('@R@',''), y.replace('@R@',''), x_arg, y_arg])\n",
    "        df = pd.DataFrame(data, columns=['Entailing Predicate','Entailed Predicate',\n",
    "                                         'X.Y=T/F Entailing Pred.','X.Y=T/F Entailed Pred.'])\n",
    "        return df\n",
    "    else:\n",
    "        data = []\n",
    "        for e in arr:\n",
    "            x, y = e.split('\\t')\n",
    "            if len(x.split()) <= length_entailing_predicate:\n",
    "                data.append([x.replace('@R@',''), y.replace('@R@','')])\n",
    "        df = pd.DataFrame(data, columns=['Entailing Predicate','Entailed Predicate'])\n",
    "        return df\n",
    "\n",
    "entailments = entailment_sorter(entailments_prestrip, length_entailing_predicate = 1, \n",
    "                                orderXY=True)\n",
    "entailing_pred = list(entailments['Entailing Predicate'])\n",
    "print(len(bias_lexicon), len(assertives), len(factives), len(hedges), \n",
    "      len(other_lexicon), len(report_verbs), len(entailing_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_vars(arr,tag_index=10):\n",
    "    POS_tags = ['CC','CD','DT','EX','FW','IN','JJ','JJR','JJS','LS','MD','NN','NNS',\n",
    "                'NNP','NNPS','PDT','POS','PRP','PRP$','RB','RBR','RBS','RP','TO','UH',\n",
    "               'VB','VBD','VBG','VBN','VBP','VBZ','WDT','WP','WP$','WRB']\n",
    "    for sentence in arr:\n",
    "        word_tag_tuples = sentence[tag_index]\n",
    "        tag_vector = np.zeros(len(POS_tags))\n",
    "        for word, tag in zip(word_tag_tuples):\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
